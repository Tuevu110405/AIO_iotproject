{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMKYaxdxHlZlkEPxCwftUWU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tuevu110405/AIO_iotproject/blob/feature%2Fupload/iotproject_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe==0.10.18"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeQqH9kR6vHt",
        "outputId": "8ac45387-a195-4dc8-dda9-75bcd7a89256"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mediapipe==0.10.18\n",
            "  Downloading mediapipe-0.10.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.18) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.18) (24.2.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.18) (24.3.25)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.18) (0.4.33)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.18) (0.4.33)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.18) (3.8.0)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.18) (1.26.4)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.18) (4.10.0.84)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.18) (4.25.5)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe==0.10.18)\n",
            "  Downloading sounddevice-0.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from mediapipe==0.10.18) (0.2.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice>=0.4.4->mediapipe==0.10.18) (1.17.1)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe==0.10.18) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe==0.10.18) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe==0.10.18) (1.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe==0.10.18) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe==0.10.18) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe==0.10.18) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe==0.10.18) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe==0.10.18) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe==0.10.18) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe==0.10.18) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mediapipe==0.10.18) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe==0.10.18) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe==0.10.18) (1.16.0)\n",
            "Downloading mediapipe-0.10.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.1/36.1 MB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sounddevice-0.5.1-py3-none-any.whl (32 kB)\n",
            "Installing collected packages: sounddevice, mediapipe\n",
            "Successfully installed mediapipe-0.10.18 sounddevice-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDsqQEMtO_gV",
        "outputId": "7037db0c-3b4b-4fde-9f8f-ff261720045b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.6.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.26.4)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.5.1+cu121)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.11.9-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n",
            "Downloading torchmetrics-1.6.0-py3-none-any.whl (926 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m926.4/926.4 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.9-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.11.9 torchmetrics-1.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1"
      ],
      "metadata": {
        "id": "ZlbGR7k87VbH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        list_label = label_dict_from_config_file(\"hand_gesture.yaml\")\n",
        "\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(63, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.Linear(128, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(128, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(128, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.6),\n",
        "            nn.Linear(128, len(list_label)\n",
        "        ))\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "    def predict(self,x,threshold=0.8):\n",
        "        logits = self(x)\n",
        "        softmax_prob = nn.Softmax(dim=1)(logits)\n",
        "        chosen_ind = torch.argmax(softmax_prob,dim=1)\n",
        "        return torch.where(softmax_prob[0,chosen_ind]>threshold,chosen_ind,-1)\n",
        "\n",
        "    def predict_with_known_class(self,x):\n",
        "        logits = self(x)\n",
        "        softmax_prob = nn.Softmax(dim=1)(logits)\n",
        "        return torch.argmax(softmax_prob,dim=1)\n",
        "\n",
        "    def score(self,logits):\n",
        "        return -torch.amax(logits,dim=1)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gYrww0sz2reI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def label_dict_from_config_file(relative_path):\n",
        "    with open(relative_path,\"r\") as f:\n",
        "       label_tag = yaml.full_load(f)[\"gestures\"]\n",
        "    return label_tag"
      ],
      "metadata": {
        "id": "JWhmAe_fQ0aJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HandLandmarksDetector():\n",
        "    def __init__(self) -> None:\n",
        "        self.mp_drawing = mp.solutions.drawing_utils\n",
        "        self.mp_drawing_styles = mp.solutions.drawing_styles\n",
        "        self.mp_hands = mp.solutions.hands\n",
        "        self.detector = self.mp_hands.Hands(False,max_num_hands=1,min_detection_confidence=0.5)\n",
        "\n",
        "    def detectHand(self,frame):\n",
        "        hands = []\n",
        "        frame = cv2.flip(frame, 1)\n",
        "        annotated_image = frame.copy()\n",
        "        results = self.detector.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "        if results.multi_hand_landmarks is not None:\n",
        "            for hand_landmarks in results.multi_hand_landmarks:\n",
        "                hand = []\n",
        "                self.mp_drawing.draw_landmarks(\n",
        "                    annotated_image,\n",
        "                    hand_landmarks,\n",
        "                    self.mp_hands.HAND_CONNECTIONS,\n",
        "                    self.mp_drawing_styles.get_default_hand_landmarks_style(),\n",
        "                    self.mp_drawing_styles.get_default_hand_connections_style())\n",
        "                for landmark in hand_landmarks.landmark:\n",
        "                    x,y,z = landmark.x,landmark.y,landmark.z\n",
        "                    hand.extend([x,y,z])\n",
        "            hands.append(hand)\n",
        "        return hands,annotated_image\n"
      ],
      "metadata": {
        "id": "WQ5mq4FtRL5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, data_file):\n",
        "        self.data = pd.read_csv(data_file)\n",
        "        self.labels = torch.from_numpy(self.data.iloc[:,0].to_numpy())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        one_hot_label = self.labels[idx]\n",
        "        torch_data = torch.from_numpy(self.data.iloc[idx,1:].to_numpy(dtype=np.float32))\n",
        "        return torch_data, one_hot_label"
      ],
      "metadata": {
        "id": "U6ibg1w6RDsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopper:\n",
        "    def __init__(self, patience=1, min_delta=0):\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.watched_metrics = np.inf\n",
        "\n",
        "    def early_stop(self, current_value):\n",
        "        if current_value < self.watched_metrics:\n",
        "            self.watched_metrics = current_value\n",
        "            self.counter = 0\n",
        "        elif current_value > (self.watched_metrics + self.min_delta):\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                return True\n",
        "        return False"
      ],
      "metadata": {
        "id": "W-_cA_IURaOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(trainloader, val_loader, model, loss_function, early_stopper, optimizer):\n",
        "    # add auroc score\n",
        "    best_vloss = 1_000_000\n",
        "    timestamp = datetime.now().strftime('%d-%m %H:%M')\n",
        "    for epoch in range(300):\n",
        "        #training step\n",
        "        model.train(True)\n",
        "        running_loss = 0.0\n",
        "        acc_train = Accuracy(num_classes=len(LIST_LABEL), task='MULTICLASS')\n",
        "        for batch_number,data in enumerate(trainloader):\n",
        "            inputs,labels = data\n",
        "\n",
        "            ################## Your Code Here ################## Q9\n",
        "\n",
        "\n",
        "            preds = model(inputs)\n",
        "            optimizer.zero_grad()\n",
        "            ####################################################\n",
        "\n",
        "            ################## Your Code Here ################## Q10\n",
        "            ''' Hoàn thành code để thực hiện tính loss dưa vào kết quả dự đoán\n",
        "            và labels, sau đó thực hiện backwward và update parameters thông qua\n",
        "            optimizer\n",
        "            '''\n",
        "            loss = loss_function(preds, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "\n",
        "            ####################################################\n",
        "\n",
        "            acc_train.update(model.predict_with_known_class(inputs), labels)\n",
        "            running_loss += loss.item()\n",
        "        avg_loss = running_loss / len(trainloader)\n",
        "        # validating step\n",
        "        model.train(False)\n",
        "        running_vloss = 0.0\n",
        "        acc_val = Accuracy(num_classes=len(LIST_LABEL), task='MULTICLASS')\n",
        "        for i, vdata in enumerate(val_loader):\n",
        "            vinputs, vlabels = vdata\n",
        "            preds = model(vinputs)\n",
        "            vloss = loss_function(preds, vlabels)\n",
        "            running_vloss += vloss.item()\n",
        "            acc_val.update(model.predict_with_known_class(vinputs), vlabels)\n",
        "\n",
        "        # Log the running loss averaged per batch\n",
        "        # for both training and validation\n",
        "        print(f\"Epoch {epoch}: \")\n",
        "        print(f\"Accuracy train:{acc_train.compute().item()}, val:{acc_val.compute().item()}\")\n",
        "        avg_vloss = running_vloss / len(val_loader)\n",
        "        print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
        "        print('Training vs. Validation Loss',\n",
        "                        { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
        "                        epoch + 1)\n",
        "        print('Training vs. Validation accuracy',\n",
        "                        { 'Training' : acc_train.compute().item()\n",
        "                        , 'Validation' : acc_val.compute().item() },\n",
        "                        epoch + 1)\n",
        "\n",
        "        # Track best performance, and save the model's state\n",
        "        if avg_vloss < best_vloss:\n",
        "            best_vloss = avg_vloss\n",
        "            best_model_path = f'./{save_path}/model_{timestamp}_{model.__class__.__name__}_best'\n",
        "            torch.save(model.state_dict(), best_model_path)\n",
        "\n",
        "        if early_stopper.early_stop(avg_vloss):\n",
        "            ################## Your Code Here ################## Q5\n",
        "            ''' Hoàn thành đoạn code bên dướ để  print ra epoch hiện tại và\n",
        "            minimum watched metric và thoát loop\n",
        "            '''\n",
        "            print(f\" stopping at epoch {epoch} , minimum : {early_stopper.watched_metrics}\")\n",
        "            break\n",
        "\n",
        "            ####################################################\n",
        "\n",
        "\n",
        "\n",
        "    model_path = f'./{save_path}/model_{timestamp}_{model.__class__.__name__}_last'\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "\n",
        "    print(acc_val.compute())\n",
        "    return model, best_model_path"
      ],
      "metadata": {
        "id": "MpQyurFcVgAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_FOLDER_PATH=\"/content/data\"\n",
        "LIST_LABEL = label_dict_from_config_file(\"hand_gesture.yaml\")\n",
        "train_path = os.path.join(DATA_FOLDER_PATH,\"landmark_train.csv\")\n",
        "val_path = os.path.join(DATA_FOLDER_PATH,\"landmark_val.csv\")\n",
        "save_path = './models'\n",
        "os.makedirs(save_path,exist_ok=True)\n",
        "\n",
        "trainset = CustomImageDataset(train_path)\n",
        "################## Your Code Here ################## Q3\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=40, shuffle=True)\n",
        "####################################################\n",
        "\n",
        "valset = CustomImageDataset(os.path.join(val_path))\n",
        "val_loader = torch.utils.data.DataLoader(valset,batch_size=50, shuffle=False)\n",
        "\n",
        "################## Your Code Here ################## Q8\n",
        "'''Hoàn thành code để thực hiện khởi tạo NeuralNetwork model đã xây dựng ở trên,\n",
        "khởi tạo hàm loss sử dụng CrossEntropyLoss và khởi tạo early stopper với patience\n",
        "là 30 và min_delta là 0.01\n",
        "'''\n",
        "model = NeuralNetwork()\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "early_stopper = EarlyStopper(patience=30, min_delta=0.01)\n",
        "####################################################\n",
        "\n",
        "################## Your Code Here ################## Q4\n",
        "'''Hoàn thành code để thực hiện cấu hình Adam optimizer cho các tham số của\n",
        "model với tốc độ học là 0.0001\n",
        "'''\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "####################################################\n",
        "\n",
        "\n",
        "model, best_model_path = train(trainloader, val_loader, model, loss_function, early_stopper, optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xIS1-c5iOvhk",
        "outputId": "88a480a2-d377-4b60-ac03-b1ef66345349"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: \n",
            "Accuracy train:0.7409695982933044, val:0.9923273921012878\n",
            "LOSS train 0.907196165326069 valid 0.14806670373218367\n",
            "Training vs. Validation Loss {'Training': 0.907196165326069, 'Validation': 0.14806670373218367} 1\n",
            "Training vs. Validation accuracy {'Training': 0.7409695982933044, 'Validation': 0.9923273921012878} 1\n",
            "Epoch 1: \n",
            "Accuracy train:0.9895437359809875, val:1.0\n",
            "LOSS train 0.06351089943639653 valid 0.002138539461157052\n",
            "Training vs. Validation Loss {'Training': 0.06351089943639653, 'Validation': 0.002138539461157052} 2\n",
            "Training vs. Validation accuracy {'Training': 0.9895437359809875, 'Validation': 1.0} 2\n",
            "Epoch 2: \n",
            "Accuracy train:0.9923954606056213, val:1.0\n",
            "LOSS train 0.025652768898685025 valid 0.001600946925094604\n",
            "Training vs. Validation Loss {'Training': 0.025652768898685025, 'Validation': 0.001600946925094604} 3\n",
            "Training vs. Validation accuracy {'Training': 0.9923954606056213, 'Validation': 1.0} 3\n",
            "Epoch 3: \n",
            "Accuracy train:0.9928707480430603, val:1.0\n",
            "LOSS train 0.02610411462571718 valid 0.0002792879323845199\n",
            "Training vs. Validation Loss {'Training': 0.02610411462571718, 'Validation': 0.0002792879323845199} 4\n",
            "Training vs. Validation accuracy {'Training': 0.9928707480430603, 'Validation': 1.0} 4\n",
            "Epoch 4: \n",
            "Accuracy train:0.9942965507507324, val:1.0\n",
            "LOSS train 0.026611908343357017 valid 0.001561940194640954\n",
            "Training vs. Validation Loss {'Training': 0.026611908343357017, 'Validation': 0.001561940194640954} 5\n",
            "Training vs. Validation accuracy {'Training': 0.9942965507507324, 'Validation': 1.0} 5\n",
            "Epoch 5: \n",
            "Accuracy train:0.9919201731681824, val:0.47698208689689636\n",
            "LOSS train 0.02715006065423126 valid 2.9328771182026685\n",
            "Training vs. Validation Loss {'Training': 0.02715006065423126, 'Validation': 2.9328771182026685} 6\n",
            "Training vs. Validation accuracy {'Training': 0.9919201731681824, 'Validation': 0.47698208689689636} 6\n",
            "Epoch 6: \n",
            "Accuracy train:0.9928707480430603, val:0.8542199730873108\n",
            "LOSS train 0.028958145079295203 valid 0.24696586511109164\n",
            "Training vs. Validation Loss {'Training': 0.028958145079295203, 'Validation': 0.24696586511109164} 7\n",
            "Training vs. Validation accuracy {'Training': 0.9928707480430603, 'Validation': 0.8542199730873108} 7\n",
            "Epoch 7: \n",
            "Accuracy train:0.9947718381881714, val:0.9296675324440002\n",
            "LOSS train 0.022305839941046148 valid 0.12585458251961512\n",
            "Training vs. Validation Loss {'Training': 0.022305839941046148, 'Validation': 0.12585458251961512} 8\n",
            "Training vs. Validation accuracy {'Training': 0.9947718381881714, 'Validation': 0.9296675324440002} 8\n",
            "Epoch 8: \n",
            "Accuracy train:0.9971482753753662, val:0.9040920734405518\n",
            "LOSS train 0.01719733540689186 valid 0.1995869789073481\n",
            "Training vs. Validation Loss {'Training': 0.01719733540689186, 'Validation': 0.1995869789073481} 9\n",
            "Training vs. Validation accuracy {'Training': 0.9971482753753662, 'Validation': 0.9040920734405518} 9\n",
            "Epoch 9: \n",
            "Accuracy train:0.9952471256256104, val:1.0\n",
            "LOSS train 0.013109740573541648 valid 0.00018816358409168288\n",
            "Training vs. Validation Loss {'Training': 0.013109740573541648, 'Validation': 0.00018816358409168288} 10\n",
            "Training vs. Validation accuracy {'Training': 0.9952471256256104, 'Validation': 1.0} 10\n",
            "Epoch 10: \n",
            "Accuracy train:0.9976235628128052, val:1.0\n",
            "LOSS train 0.012876119592308314 valid 0.0001713322621483826\n",
            "Training vs. Validation Loss {'Training': 0.012876119592308314, 'Validation': 0.0001713322621483826} 11\n",
            "Training vs. Validation accuracy {'Training': 0.9976235628128052, 'Validation': 1.0} 11\n",
            "Epoch 11: \n",
            "Accuracy train:0.9976235628128052, val:1.0\n",
            "LOSS train 0.010686676148529755 valid 0.0009003349654985726\n",
            "Training vs. Validation Loss {'Training': 0.010686676148529755, 'Validation': 0.0009003349654985726} 12\n",
            "Training vs. Validation accuracy {'Training': 0.9976235628128052, 'Validation': 1.0} 12\n",
            "Epoch 12: \n",
            "Accuracy train:0.9952471256256104, val:1.0\n",
            "LOSS train 0.025103517027227493 valid 0.0018524415486771417\n",
            "Training vs. Validation Loss {'Training': 0.025103517027227493, 'Validation': 0.0018524415486771417} 13\n",
            "Training vs. Validation accuracy {'Training': 0.9952471256256104, 'Validation': 1.0} 13\n",
            "Epoch 13: \n",
            "Accuracy train:0.9971482753753662, val:1.0\n",
            "LOSS train 0.01918359028553274 valid 0.0004548024914399207\n",
            "Training vs. Validation Loss {'Training': 0.01918359028553274, 'Validation': 0.0004548024914399207} 14\n",
            "Training vs. Validation accuracy {'Training': 0.9971482753753662, 'Validation': 1.0} 14\n",
            "Epoch 14: \n",
            "Accuracy train:0.9957224130630493, val:0.9961636662483215\n",
            "LOSS train 0.014791886433398896 valid 0.011383819957899277\n",
            "Training vs. Validation Loss {'Training': 0.014791886433398896, 'Validation': 0.011383819957899277} 15\n",
            "Training vs. Validation accuracy {'Training': 0.9957224130630493, 'Validation': 0.9961636662483215} 15\n",
            "Epoch 15: \n",
            "Accuracy train:0.9966729879379272, val:1.0\n",
            "LOSS train 0.010557772146092007 valid 5.330822889959563e-05\n",
            "Training vs. Validation Loss {'Training': 0.010557772146092007, 'Validation': 5.330822889959563e-05} 16\n",
            "Training vs. Validation accuracy {'Training': 0.9966729879379272, 'Validation': 1.0} 16\n",
            "Epoch 16: \n",
            "Accuracy train:0.9980988502502441, val:1.0\n",
            "LOSS train 0.013095895455543936 valid 0.0007260831461167738\n",
            "Training vs. Validation Loss {'Training': 0.013095895455543936, 'Validation': 0.0007260831461167738} 17\n",
            "Training vs. Validation accuracy {'Training': 0.9980988502502441, 'Validation': 1.0} 17\n",
            "Epoch 17: \n",
            "Accuracy train:0.9957224130630493, val:0.9961636662483215\n",
            "LOSS train 0.020589792404657685 valid 0.008860857078644813\n",
            "Training vs. Validation Loss {'Training': 0.020589792404657685, 'Validation': 0.008860857078644813} 18\n",
            "Training vs. Validation accuracy {'Training': 0.9957224130630493, 'Validation': 0.9961636662483215} 18\n",
            "Epoch 18: \n",
            "Accuracy train:0.9966729879379272, val:1.0\n",
            "LOSS train 0.016014323249623458 valid 0.00014604585148175753\n",
            "Training vs. Validation Loss {'Training': 0.016014323249623458, 'Validation': 0.00014604585148175753} 19\n",
            "Training vs. Validation accuracy {'Training': 0.9966729879379272, 'Validation': 1.0} 19\n",
            "Epoch 19: \n",
            "Accuracy train:0.9961977005004883, val:1.0\n",
            "LOSS train 0.015604197290777624 valid 0.00036798321081643603\n",
            "Training vs. Validation Loss {'Training': 0.015604197290777624, 'Validation': 0.00036798321081643603} 20\n",
            "Training vs. Validation accuracy {'Training': 0.9961977005004883, 'Validation': 1.0} 20\n",
            "Epoch 20: \n",
            "Accuracy train:0.9971482753753662, val:0.9936061501502991\n",
            "LOSS train 0.011471003018602956 valid 0.014371972052049209\n",
            "Training vs. Validation Loss {'Training': 0.011471003018602956, 'Validation': 0.014371972052049209} 21\n",
            "Training vs. Validation accuracy {'Training': 0.9971482753753662, 'Validation': 0.9936061501502991} 21\n",
            "Epoch 21: \n",
            "Accuracy train:0.9971482753753662, val:1.0\n",
            "LOSS train 0.009526564366923302 valid 1.4258458429949883e-05\n",
            "Training vs. Validation Loss {'Training': 0.009526564366923302, 'Validation': 1.4258458429949883e-05} 22\n",
            "Training vs. Validation accuracy {'Training': 0.9971482753753662, 'Validation': 1.0} 22\n",
            "Epoch 22: \n",
            "Accuracy train:0.9966729879379272, val:1.0\n",
            "LOSS train 0.005301211162798111 valid 9.99356404829399e-05\n",
            "Training vs. Validation Loss {'Training': 0.005301211162798111, 'Validation': 9.99356404829399e-05} 23\n",
            "Training vs. Validation accuracy {'Training': 0.9966729879379272, 'Validation': 1.0} 23\n",
            "Epoch 23: \n",
            "Accuracy train:0.9976235628128052, val:1.0\n",
            "LOSS train 0.006749436654436582 valid 1.1906703592287626e-05\n",
            "Training vs. Validation Loss {'Training': 0.006749436654436582, 'Validation': 1.1906703592287626e-05} 24\n",
            "Training vs. Validation accuracy {'Training': 0.9976235628128052, 'Validation': 1.0} 24\n",
            "Epoch 24: \n",
            "Accuracy train:0.9947718381881714, val:0.9987212419509888\n",
            "LOSS train 0.035282565421783936 valid 0.003832147998642732\n",
            "Training vs. Validation Loss {'Training': 0.035282565421783936, 'Validation': 0.003832147998642732} 25\n",
            "Training vs. Validation accuracy {'Training': 0.9947718381881714, 'Validation': 0.9987212419509888} 25\n",
            "Epoch 25: \n",
            "Accuracy train:0.9942965507507324, val:1.0\n",
            "LOSS train 0.0242931426113981 valid 0.0006806107948251761\n",
            "Training vs. Validation Loss {'Training': 0.0242931426113981, 'Validation': 0.0006806107948251761} 26\n",
            "Training vs. Validation accuracy {'Training': 0.9942965507507324, 'Validation': 1.0} 26\n",
            "Epoch 26: \n",
            "Accuracy train:0.9985741376876831, val:1.0\n",
            "LOSS train 0.01202500101457842 valid 3.688084247399637e-05\n",
            "Training vs. Validation Loss {'Training': 0.01202500101457842, 'Validation': 3.688084247399637e-05} 27\n",
            "Training vs. Validation accuracy {'Training': 0.9985741376876831, 'Validation': 1.0} 27\n",
            "Epoch 27: \n",
            "Accuracy train:0.9957224130630493, val:1.0\n",
            "LOSS train 0.01045659202546236 valid 9.680044338766791e-06\n",
            "Training vs. Validation Loss {'Training': 0.01045659202546236, 'Validation': 9.680044338766791e-06} 28\n",
            "Training vs. Validation accuracy {'Training': 0.9957224130630493, 'Validation': 1.0} 28\n",
            "Epoch 28: \n",
            "Accuracy train:0.9952471256256104, val:0.9987212419509888\n",
            "LOSS train 0.010189183339945267 valid 0.0011685131711125507\n",
            "Training vs. Validation Loss {'Training': 0.010189183339945267, 'Validation': 0.0011685131711125507} 29\n",
            "Training vs. Validation accuracy {'Training': 0.9952471256256104, 'Validation': 0.9987212419509888} 29\n",
            "Epoch 29: \n",
            "Accuracy train:0.9976235628128052, val:1.0\n",
            "LOSS train 0.019117443558261928 valid 0.002510093862143181\n",
            "Training vs. Validation Loss {'Training': 0.019117443558261928, 'Validation': 0.002510093862143181} 30\n",
            "Training vs. Validation accuracy {'Training': 0.9976235628128052, 'Validation': 1.0} 30\n",
            "Epoch 30: \n",
            "Accuracy train:0.9976235628128052, val:1.0\n",
            "LOSS train 0.009927751126595913 valid 2.960532908641289e-05\n",
            "Training vs. Validation Loss {'Training': 0.009927751126595913, 'Validation': 2.960532908641289e-05} 31\n",
            "Training vs. Validation accuracy {'Training': 0.9976235628128052, 'Validation': 1.0} 31\n",
            "Epoch 31: \n",
            "Accuracy train:0.9980988502502441, val:0.9987212419509888\n",
            "LOSS train 0.009027582957677846 valid 0.003324441645293552\n",
            "Training vs. Validation Loss {'Training': 0.009027582957677846, 'Validation': 0.003324441645293552} 32\n",
            "Training vs. Validation accuracy {'Training': 0.9980988502502441, 'Validation': 0.9987212419509888} 32\n",
            "Epoch 32: \n",
            "Accuracy train:0.9971482753753662, val:0.9808183908462524\n",
            "LOSS train 0.014584726337694897 valid 0.037657381139956675\n",
            "Training vs. Validation Loss {'Training': 0.014584726337694897, 'Validation': 0.037657381139956675} 33\n",
            "Training vs. Validation accuracy {'Training': 0.9971482753753662, 'Validation': 0.9808183908462524} 33\n",
            "Epoch 33: \n",
            "Accuracy train:0.9957224130630493, val:1.0\n",
            "LOSS train 0.009789072277580656 valid 1.3643701254895113e-05\n",
            "Training vs. Validation Loss {'Training': 0.009789072277580656, 'Validation': 1.3643701254895113e-05} 34\n",
            "Training vs. Validation accuracy {'Training': 0.9957224130630493, 'Validation': 1.0} 34\n",
            "Epoch 34: \n",
            "Accuracy train:0.9971482753753662, val:1.0\n",
            "LOSS train 0.006975622404391991 valid 4.6820638348599175e-06\n",
            "Training vs. Validation Loss {'Training': 0.006975622404391991, 'Validation': 4.6820638348599175e-06} 35\n",
            "Training vs. Validation accuracy {'Training': 0.9971482753753662, 'Validation': 1.0} 35\n",
            "Epoch 35: \n",
            "Accuracy train:0.9976235628128052, val:1.0\n",
            "LOSS train 0.011400093568295662 valid 0.00011984940955755974\n",
            "Training vs. Validation Loss {'Training': 0.011400093568295662, 'Validation': 0.00011984940955755974} 36\n",
            "Training vs. Validation accuracy {'Training': 0.9976235628128052, 'Validation': 1.0} 36\n",
            "Epoch 36: \n",
            "Accuracy train:0.9980988502502441, val:1.0\n",
            "LOSS train 0.00857198984213371 valid 0.000845607706725815\n",
            "Training vs. Validation Loss {'Training': 0.00857198984213371, 'Validation': 0.000845607706725815} 37\n",
            "Training vs. Validation accuracy {'Training': 0.9980988502502441, 'Validation': 1.0} 37\n",
            "Epoch 37: \n",
            "Accuracy train:0.9985741376876831, val:1.0\n",
            "LOSS train 0.005969524486437945 valid 1.8738219802916234e-05\n",
            "Training vs. Validation Loss {'Training': 0.005969524486437945, 'Validation': 1.8738219802916234e-05} 38\n",
            "Training vs. Validation accuracy {'Training': 0.9985741376876831, 'Validation': 1.0} 38\n",
            "Epoch 38: \n",
            "Accuracy train:0.9980988502502441, val:1.0\n",
            "LOSS train 0.006387116350797785 valid 0.00011907544890832344\n",
            "Training vs. Validation Loss {'Training': 0.006387116350797785, 'Validation': 0.00011907544890832344} 39\n",
            "Training vs. Validation accuracy {'Training': 0.9980988502502441, 'Validation': 1.0} 39\n",
            "Epoch 39: \n",
            "Accuracy train:0.9985741376876831, val:1.0\n",
            "LOSS train 0.009518701238808923 valid 7.011777466958691e-05\n",
            "Training vs. Validation Loss {'Training': 0.009518701238808923, 'Validation': 7.011777466958691e-05} 40\n",
            "Training vs. Validation accuracy {'Training': 0.9985741376876831, 'Validation': 1.0} 40\n",
            "Epoch 40: \n",
            "Accuracy train:0.9976235628128052, val:1.0\n",
            "LOSS train 0.015303775294324744 valid 0.0004330252441508975\n",
            "Training vs. Validation Loss {'Training': 0.015303775294324744, 'Validation': 0.0004330252441508975} 41\n",
            "Training vs. Validation accuracy {'Training': 0.9976235628128052, 'Validation': 1.0} 41\n",
            "Epoch 41: \n",
            "Accuracy train:0.9985741376876831, val:1.0\n",
            "LOSS train 0.012385193221766627 valid 5.380937382537532e-05\n",
            "Training vs. Validation Loss {'Training': 0.012385193221766627, 'Validation': 5.380937382537532e-05} 42\n",
            "Training vs. Validation accuracy {'Training': 0.9985741376876831, 'Validation': 1.0} 42\n",
            "Epoch 42: \n",
            "Accuracy train:0.999524712562561, val:1.0\n",
            "LOSS train 0.004524084109364611 valid 0.00019595095364813298\n",
            "Training vs. Validation Loss {'Training': 0.004524084109364611, 'Validation': 0.00019595095364813298} 43\n",
            "Training vs. Validation accuracy {'Training': 0.999524712562561, 'Validation': 1.0} 43\n",
            "Epoch 43: \n",
            "Accuracy train:0.9985741376876831, val:1.0\n",
            "LOSS train 0.010600138688048147 valid 1.4246042661980596e-05\n",
            "Training vs. Validation Loss {'Training': 0.010600138688048147, 'Validation': 1.4246042661980596e-05} 44\n",
            "Training vs. Validation accuracy {'Training': 0.9985741376876831, 'Validation': 1.0} 44\n",
            "Epoch 44: \n",
            "Accuracy train:0.9976235628128052, val:1.0\n",
            "LOSS train 0.006381676479646077 valid 9.396379084353201e-05\n",
            "Training vs. Validation Loss {'Training': 0.006381676479646077, 'Validation': 9.396379084353201e-05} 45\n",
            "Training vs. Validation accuracy {'Training': 0.9976235628128052, 'Validation': 1.0} 45\n",
            "Epoch 45: \n",
            "Accuracy train:0.9976235628128052, val:1.0\n",
            "LOSS train 0.008518765236178023 valid 1.4471699921969616e-05\n",
            "Training vs. Validation Loss {'Training': 0.008518765236178023, 'Validation': 1.4471699921969616e-05} 46\n",
            "Training vs. Validation accuracy {'Training': 0.9976235628128052, 'Validation': 1.0} 46\n",
            "Epoch 46: \n",
            "Accuracy train:0.9990494251251221, val:1.0\n",
            "LOSS train 0.00502601123525034 valid 6.149530069610165e-07\n",
            "Training vs. Validation Loss {'Training': 0.00502601123525034, 'Validation': 6.149530069610165e-07} 47\n",
            "Training vs. Validation accuracy {'Training': 0.9990494251251221, 'Validation': 1.0} 47\n",
            "Epoch 47: \n",
            "Accuracy train:0.999524712562561, val:1.0\n",
            "LOSS train 0.00478260357393529 valid 1.8793046513976286e-06\n",
            "Training vs. Validation Loss {'Training': 0.00478260357393529, 'Validation': 1.8793046513976286e-06} 48\n",
            "Training vs. Validation accuracy {'Training': 0.999524712562561, 'Validation': 1.0} 48\n",
            "Epoch 48: \n",
            "Accuracy train:0.9980988502502441, val:1.0\n",
            "LOSS train 0.007513088041116374 valid 4.268949650665377e-05\n",
            "Training vs. Validation Loss {'Training': 0.007513088041116374, 'Validation': 4.268949650665377e-05} 49\n",
            "Training vs. Validation accuracy {'Training': 0.9980988502502441, 'Validation': 1.0} 49\n",
            "Epoch 49: \n",
            "Accuracy train:0.9980988502502441, val:1.0\n",
            "LOSS train 0.005874014756663423 valid 0.0001288780205923601\n",
            "Training vs. Validation Loss {'Training': 0.005874014756663423, 'Validation': 0.0001288780205923601} 50\n",
            "Training vs. Validation accuracy {'Training': 0.9980988502502441, 'Validation': 1.0} 50\n",
            "Epoch 50: \n",
            "Accuracy train:0.9966729879379272, val:0.9974424839019775\n",
            "LOSS train 0.018909126606507377 valid 0.0036649917053139802\n",
            "Training vs. Validation Loss {'Training': 0.018909126606507377, 'Validation': 0.0036649917053139802} 51\n",
            "Training vs. Validation accuracy {'Training': 0.9966729879379272, 'Validation': 0.9974424839019775} 51\n",
            "Epoch 51: \n",
            "Accuracy train:0.9966729879379272, val:1.0\n",
            "LOSS train 0.006041152505977667 valid 6.573005540477794e-05\n",
            "Training vs. Validation Loss {'Training': 0.006041152505977667, 'Validation': 6.573005540477794e-05} 52\n",
            "Training vs. Validation accuracy {'Training': 0.9966729879379272, 'Validation': 1.0} 52\n",
            "Epoch 52: \n",
            "Accuracy train:0.9966729879379272, val:0.9833759665489197\n",
            "LOSS train 0.01638421020683347 valid 0.05674359136162366\n",
            "Training vs. Validation Loss {'Training': 0.01638421020683347, 'Validation': 0.05674359136162366} 53\n",
            "Training vs. Validation accuracy {'Training': 0.9966729879379272, 'Validation': 0.9833759665489197} 53\n",
            "Epoch 53: \n",
            "Accuracy train:0.9980988502502441, val:1.0\n",
            "LOSS train 0.015360361638982486 valid 0.00027260722888072797\n",
            "Training vs. Validation Loss {'Training': 0.015360361638982486, 'Validation': 0.00027260722888072797} 54\n",
            "Training vs. Validation accuracy {'Training': 0.9980988502502441, 'Validation': 1.0} 54\n",
            "Epoch 54: \n",
            "Accuracy train:0.9971482753753662, val:0.9987212419509888\n",
            "LOSS train 0.007223539197561963 valid 0.0028703734149823634\n",
            "Training vs. Validation Loss {'Training': 0.007223539197561963, 'Validation': 0.0028703734149823634} 55\n",
            "Training vs. Validation accuracy {'Training': 0.9971482753753662, 'Validation': 0.9987212419509888} 55\n",
            "Epoch 55: \n",
            "Accuracy train:0.9980988502502441, val:1.0\n",
            "LOSS train 0.004140721506769725 valid 4.0507168025838425e-05\n",
            "Training vs. Validation Loss {'Training': 0.004140721506769725, 'Validation': 4.0507168025838425e-05} 56\n",
            "Training vs. Validation accuracy {'Training': 0.9980988502502441, 'Validation': 1.0} 56\n",
            "Epoch 56: \n",
            "Accuracy train:0.9990494251251221, val:1.0\n",
            "LOSS train 0.009846896571513565 valid 2.58929909899841e-05\n",
            "Training vs. Validation Loss {'Training': 0.009846896571513565, 'Validation': 2.58929909899841e-05} 57\n",
            "Training vs. Validation accuracy {'Training': 0.9990494251251221, 'Validation': 1.0} 57\n",
            "Epoch 57: \n",
            "Accuracy train:0.9976235628128052, val:0.9948849081993103\n",
            "LOSS train 0.006536206991991351 valid 0.022714361590316395\n",
            "Training vs. Validation Loss {'Training': 0.006536206991991351, 'Validation': 0.022714361590316395} 58\n",
            "Training vs. Validation accuracy {'Training': 0.9976235628128052, 'Validation': 0.9948849081993103} 58\n",
            "Epoch 58: \n",
            "Accuracy train:0.9966729879379272, val:0.9987212419509888\n",
            "LOSS train 0.008630261860024854 valid 0.007449416377443868\n",
            "Training vs. Validation Loss {'Training': 0.008630261860024854, 'Validation': 0.007449416377443868} 59\n",
            "Training vs. Validation accuracy {'Training': 0.9966729879379272, 'Validation': 0.9987212419509888} 59\n",
            "Epoch 59: \n",
            "Accuracy train:0.9985741376876831, val:1.0\n",
            "LOSS train 0.009739059657528382 valid 5.178754808532471e-05\n",
            "Training vs. Validation Loss {'Training': 0.009739059657528382, 'Validation': 5.178754808532471e-05} 60\n",
            "Training vs. Validation accuracy {'Training': 0.9985741376876831, 'Validation': 1.0} 60\n",
            "Epoch 60: \n",
            "Accuracy train:0.9980988502502441, val:0.9987212419509888\n",
            "LOSS train 0.005282471229001426 valid 0.0035187508904006015\n",
            "Training vs. Validation Loss {'Training': 0.005282471229001426, 'Validation': 0.0035187508904006015} 61\n",
            "Training vs. Validation accuracy {'Training': 0.9980988502502441, 'Validation': 0.9987212419509888} 61\n",
            "Epoch 61: \n",
            "Accuracy train:0.9971482753753662, val:1.0\n",
            "LOSS train 0.006824063013482373 valid 0.00034918457184696106\n",
            "Training vs. Validation Loss {'Training': 0.006824063013482373, 'Validation': 0.00034918457184696106} 62\n",
            "Training vs. Validation accuracy {'Training': 0.9971482753753662, 'Validation': 1.0} 62\n",
            "Epoch 62: \n",
            "Accuracy train:0.9980988502502441, val:1.0\n",
            "LOSS train 0.004908607526980425 valid 2.1642210290551134e-06\n",
            "Training vs. Validation Loss {'Training': 0.004908607526980425, 'Validation': 2.1642210290551134e-06} 63\n",
            "Training vs. Validation accuracy {'Training': 0.9980988502502441, 'Validation': 1.0} 63\n",
            "Epoch 63: \n",
            "Accuracy train:0.9976235628128052, val:0.9987212419509888\n",
            "LOSS train 0.009308268754432233 valid 0.0020989715561716693\n",
            "Training vs. Validation Loss {'Training': 0.009308268754432233, 'Validation': 0.0020989715561716693} 64\n",
            "Training vs. Validation accuracy {'Training': 0.9976235628128052, 'Validation': 0.9987212419509888} 64\n",
            "Epoch 64: \n",
            "Accuracy train:0.9980988502502441, val:0.9987212419509888\n",
            "LOSS train 0.01057985990901044 valid 0.0023720230720515045\n",
            "Training vs. Validation Loss {'Training': 0.01057985990901044, 'Validation': 0.0023720230720515045} 65\n",
            "Training vs. Validation accuracy {'Training': 0.9980988502502441, 'Validation': 0.9987212419509888} 65\n",
            "Epoch 65: \n",
            "Accuracy train:0.9976235628128052, val:1.0\n",
            "LOSS train 0.01164438064435397 valid 0.0036826684665447473\n",
            "Training vs. Validation Loss {'Training': 0.01164438064435397, 'Validation': 0.0036826684665447473} 66\n",
            "Training vs. Validation accuracy {'Training': 0.9976235628128052, 'Validation': 1.0} 66\n",
            "Epoch 66: \n",
            "Accuracy train:0.9971482753753662, val:1.0\n",
            "LOSS train 0.012272104593065242 valid 2.1778474338596254e-05\n",
            "Training vs. Validation Loss {'Training': 0.012272104593065242, 'Validation': 2.1778474338596254e-05} 67\n",
            "Training vs. Validation accuracy {'Training': 0.9971482753753662, 'Validation': 1.0} 67\n",
            "Epoch 67: \n",
            "Accuracy train:1.0, val:1.0\n",
            "LOSS train 0.0035788905806067254 valid 3.087508781085546e-06\n",
            "Training vs. Validation Loss {'Training': 0.0035788905806067254, 'Validation': 3.087508781085546e-06} 68\n",
            "Training vs. Validation accuracy {'Training': 1.0, 'Validation': 1.0} 68\n",
            "Epoch 68: \n",
            "Accuracy train:0.9985741376876831, val:0.9974424839019775\n",
            "LOSS train 0.02138087172396002 valid 0.006662406692328926\n",
            "Training vs. Validation Loss {'Training': 0.02138087172396002, 'Validation': 0.006662406692328926} 69\n",
            "Training vs. Validation accuracy {'Training': 0.9985741376876831, 'Validation': 0.9974424839019775} 69\n",
            "Epoch 69: \n",
            "Accuracy train:0.999524712562561, val:0.9987212419509888\n",
            "LOSS train 0.006132797205460297 valid 0.0020586809422519503\n",
            "Training vs. Validation Loss {'Training': 0.006132797205460297, 'Validation': 0.0020586809422519503} 70\n",
            "Training vs. Validation accuracy {'Training': 0.999524712562561, 'Validation': 0.9987212419509888} 70\n",
            "Epoch 70: \n",
            "Accuracy train:0.9976235628128052, val:1.0\n",
            "LOSS train 0.007991340120446144 valid 3.33415461701847e-05\n",
            "Training vs. Validation Loss {'Training': 0.007991340120446144, 'Validation': 3.33415461701847e-05} 71\n",
            "Training vs. Validation accuracy {'Training': 0.9976235628128052, 'Validation': 1.0} 71\n",
            "Epoch 71: \n",
            "Accuracy train:0.9980988502502441, val:1.0\n",
            "LOSS train 0.014851113852805525 valid 4.4766760329828514e-06\n",
            "Training vs. Validation Loss {'Training': 0.014851113852805525, 'Validation': 4.4766760329828514e-06} 72\n",
            "Training vs. Validation accuracy {'Training': 0.9980988502502441, 'Validation': 1.0} 72\n",
            "Epoch 72: \n",
            "Accuracy train:0.9990494251251221, val:1.0\n",
            "LOSS train 0.0037687709087197807 valid 1.3826527298643754e-06\n",
            "Training vs. Validation Loss {'Training': 0.0037687709087197807, 'Validation': 1.3826527298643754e-06} 73\n",
            "Training vs. Validation accuracy {'Training': 0.9990494251251221, 'Validation': 1.0} 73\n",
            "Epoch 73: \n",
            "Accuracy train:0.9985741376876831, val:1.0\n",
            "LOSS train 0.0060202208688027005 valid 2.2488822708277567e-05\n",
            "Training vs. Validation Loss {'Training': 0.0060202208688027005, 'Validation': 2.2488822708277567e-05} 74\n",
            "Training vs. Validation accuracy {'Training': 0.9985741376876831, 'Validation': 1.0} 74\n",
            "Epoch 74: \n",
            "Accuracy train:0.9990494251251221, val:1.0\n",
            "LOSS train 0.004686926294181042 valid 0.00020393010742747464\n",
            "Training vs. Validation Loss {'Training': 0.004686926294181042, 'Validation': 0.00020393010742747464} 75\n",
            "Training vs. Validation accuracy {'Training': 0.9990494251251221, 'Validation': 1.0} 75\n",
            "Epoch 75: \n",
            "Accuracy train:1.0, val:1.0\n",
            "LOSS train 0.0035039713526408755 valid 8.809885574334597e-06\n",
            "Training vs. Validation Loss {'Training': 0.0035039713526408755, 'Validation': 8.809885574334597e-06} 76\n",
            "Training vs. Validation accuracy {'Training': 1.0, 'Validation': 1.0} 76\n",
            "Epoch 76: \n",
            "Accuracy train:0.9947718381881714, val:0.9961636662483215\n",
            "LOSS train 0.016611353553670133 valid 0.007149854141360601\n",
            "Training vs. Validation Loss {'Training': 0.016611353553670133, 'Validation': 0.007149854141360601} 77\n",
            "Training vs. Validation accuracy {'Training': 0.9947718381881714, 'Validation': 0.9961636662483215} 77\n",
            "Epoch 77: \n",
            "Accuracy train:0.9966729879379272, val:1.0\n",
            "LOSS train 0.009289748382532294 valid 0.0001443481505373767\n",
            "Training vs. Validation Loss {'Training': 0.009289748382532294, 'Validation': 0.0001443481505373767} 78\n",
            "Training vs. Validation accuracy {'Training': 0.9966729879379272, 'Validation': 1.0} 78\n",
            "Epoch 78: \n",
            "Accuracy train:0.9980988502502441, val:1.0\n",
            "LOSS train 0.0031539621968005244 valid 6.747692276209971e-06\n",
            "Training vs. Validation Loss {'Training': 0.0031539621968005244, 'Validation': 6.747692276209971e-06} 79\n",
            "Training vs. Validation accuracy {'Training': 0.9980988502502441, 'Validation': 1.0} 79\n",
            "Epoch 79: \n",
            "Accuracy train:0.9980988502502441, val:1.0\n",
            "LOSS train 0.0021513666883347126 valid 2.2541196822989384e-05\n",
            "Training vs. Validation Loss {'Training': 0.0021513666883347126, 'Validation': 2.2541196822989384e-05} 80\n",
            "Training vs. Validation accuracy {'Training': 0.9980988502502441, 'Validation': 1.0} 80\n",
            "Epoch 80: \n",
            "Accuracy train:0.9985741376876831, val:1.0\n",
            "LOSS train 0.0024242308337083813 valid 2.4482027530248196e-07\n",
            "Training vs. Validation Loss {'Training': 0.0024242308337083813, 'Validation': 2.4482027530248196e-07} 81\n",
            "Training vs. Validation accuracy {'Training': 0.9985741376876831, 'Validation': 1.0} 81\n",
            "Epoch 81: \n",
            "Accuracy train:0.999524712562561, val:1.0\n",
            "LOSS train 0.0037157681312546286 valid 2.513265929426911e-06\n",
            "Training vs. Validation Loss {'Training': 0.0037157681312546286, 'Validation': 2.513265929426911e-06} 82\n",
            "Training vs. Validation accuracy {'Training': 0.999524712562561, 'Validation': 1.0} 82\n",
            "Epoch 82: \n",
            "Accuracy train:0.9985741376876831, val:1.0\n",
            "LOSS train 0.002230035577393313 valid 6.562433796375444e-07\n",
            "Training vs. Validation Loss {'Training': 0.002230035577393313, 'Validation': 6.562433796375444e-07} 83\n",
            "Training vs. Validation accuracy {'Training': 0.9985741376876831, 'Validation': 1.0} 83\n",
            "Epoch 83: \n",
            "Accuracy train:0.9976235628128052, val:0.9987212419509888\n",
            "LOSS train 0.010022361049970882 valid 0.0026195316219622122\n",
            "Training vs. Validation Loss {'Training': 0.010022361049970882, 'Validation': 0.0026195316219622122} 84\n",
            "Training vs. Validation accuracy {'Training': 0.9976235628128052, 'Validation': 0.9987212419509888} 84\n",
            "Epoch 84: \n",
            "Accuracy train:0.9985741376876831, val:1.0\n",
            "LOSS train 0.009785366828029236 valid 0.00019323424472261763\n",
            "Training vs. Validation Loss {'Training': 0.009785366828029236, 'Validation': 0.00019323424472261763} 85\n",
            "Training vs. Validation accuracy {'Training': 0.9985741376876831, 'Validation': 1.0} 85\n",
            "Epoch 85: \n",
            "Accuracy train:0.9990494251251221, val:1.0\n",
            "LOSS train 0.0033774896119640923 valid 0.000617733491233341\n",
            "Training vs. Validation Loss {'Training': 0.0033774896119640923, 'Validation': 0.000617733491233341} 86\n",
            "Training vs. Validation accuracy {'Training': 0.9990494251251221, 'Validation': 1.0} 86\n",
            "Epoch 86: \n",
            "Accuracy train:0.9990494251251221, val:1.0\n",
            "LOSS train 0.005993147722755524 valid 4.6244550332613654e-05\n",
            "Training vs. Validation Loss {'Training': 0.005993147722755524, 'Validation': 4.6244550332613654e-05} 87\n",
            "Training vs. Validation accuracy {'Training': 0.9990494251251221, 'Validation': 1.0} 87\n",
            "Epoch 87: \n",
            "Accuracy train:0.9961977005004883, val:1.0\n",
            "LOSS train 0.010401343969267642 valid 3.5045309365877575e-06\n",
            "Training vs. Validation Loss {'Training': 0.010401343969267642, 'Validation': 3.5045309365877575e-06} 88\n",
            "Training vs. Validation accuracy {'Training': 0.9961977005004883, 'Validation': 1.0} 88\n",
            "Epoch 88: \n",
            "Accuracy train:0.9990494251251221, val:1.0\n",
            "LOSS train 0.009669334194552341 valid 1.5374947204271905e-06\n",
            "Training vs. Validation Loss {'Training': 0.009669334194552341, 'Validation': 1.5374947204271905e-06} 89\n",
            "Training vs. Validation accuracy {'Training': 0.9990494251251221, 'Validation': 1.0} 89\n",
            "Epoch 89: \n",
            "Accuracy train:0.9976235628128052, val:1.0\n",
            "LOSS train 0.004916144374003536 valid 4.8053599633807176e-05\n",
            "Training vs. Validation Loss {'Training': 0.004916144374003536, 'Validation': 4.8053599633807176e-05} 90\n",
            "Training vs. Validation accuracy {'Training': 0.9976235628128052, 'Validation': 1.0} 90\n",
            "Epoch 90: \n",
            "Accuracy train:0.9990494251251221, val:1.0\n",
            "LOSS train 0.004294520335556712 valid 2.6225779159450013e-08\n",
            "Training vs. Validation Loss {'Training': 0.004294520335556712, 'Validation': 2.6225779159450013e-08} 91\n",
            "Training vs. Validation accuracy {'Training': 0.9990494251251221, 'Validation': 1.0} 91\n",
            "Epoch 91: \n",
            "Accuracy train:0.9976235628128052, val:0.9987212419509888\n",
            "LOSS train 0.016444580223086855 valid 0.0013575589982655623\n",
            "Training vs. Validation Loss {'Training': 0.016444580223086855, 'Validation': 0.0013575589982655623} 92\n",
            "Training vs. Validation accuracy {'Training': 0.9976235628128052, 'Validation': 0.9987212419509888} 92\n",
            "Epoch 92: \n",
            "Accuracy train:0.9980988502502441, val:1.0\n",
            "LOSS train 0.003685170781986411 valid 1.7828643466388794e-05\n",
            "Training vs. Validation Loss {'Training': 0.003685170781986411, 'Validation': 1.7828643466388794e-05} 93\n",
            "Training vs. Validation accuracy {'Training': 0.9980988502502441, 'Validation': 1.0} 93\n",
            "Epoch 93: \n",
            "Accuracy train:0.999524712562561, val:1.0\n",
            "LOSS train 0.0030759024031171847 valid 8.702729865028846e-06\n",
            "Training vs. Validation Loss {'Training': 0.0030759024031171847, 'Validation': 8.702729865028846e-06} 94\n",
            "Training vs. Validation accuracy {'Training': 0.999524712562561, 'Validation': 1.0} 94\n",
            "Epoch 94: \n",
            "Accuracy train:0.9985741376876831, val:0.9987212419509888\n",
            "LOSS train 0.004425616651874546 valid 0.004414432458570872\n",
            "Training vs. Validation Loss {'Training': 0.004425616651874546, 'Validation': 0.004414432458570872} 95\n",
            "Training vs. Validation accuracy {'Training': 0.9985741376876831, 'Validation': 0.9987212419509888} 95\n",
            "Epoch 95: \n",
            "Accuracy train:0.999524712562561, val:1.0\n",
            "LOSS train 0.003181367559518377 valid 0.0001429048221318896\n",
            "Training vs. Validation Loss {'Training': 0.003181367559518377, 'Validation': 0.0001429048221318896} 96\n",
            "Training vs. Validation accuracy {'Training': 0.999524712562561, 'Validation': 1.0} 96\n",
            "Epoch 96: \n",
            "Accuracy train:1.0, val:1.0\n",
            "LOSS train 0.0037308161052875947 valid 1.1882204500546223e-05\n",
            "Training vs. Validation Loss {'Training': 0.0037308161052875947, 'Validation': 1.1882204500546223e-05} 97\n",
            "Training vs. Validation accuracy {'Training': 1.0, 'Validation': 1.0} 97\n",
            "Epoch 97: \n",
            "Accuracy train:0.9980988502502441, val:0.9974424839019775\n",
            "LOSS train 0.008524781541077792 valid 0.018766429996527556\n",
            "Training vs. Validation Loss {'Training': 0.008524781541077792, 'Validation': 0.018766429996527556} 98\n",
            "Training vs. Validation accuracy {'Training': 0.9980988502502441, 'Validation': 0.9974424839019775} 98\n",
            "Epoch 98: \n",
            "Accuracy train:0.9976235628128052, val:1.0\n",
            "LOSS train 0.012163685814726932 valid 0.0006049742014077042\n",
            "Training vs. Validation Loss {'Training': 0.012163685814726932, 'Validation': 0.0006049742014077042} 99\n",
            "Training vs. Validation accuracy {'Training': 0.9976235628128052, 'Validation': 1.0} 99\n",
            "Epoch 99: \n",
            "Accuracy train:0.9980988502502441, val:1.0\n",
            "LOSS train 0.007252165449440519 valid 0.000336407920654036\n",
            "Training vs. Validation Loss {'Training': 0.007252165449440519, 'Validation': 0.000336407920654036} 100\n",
            "Training vs. Validation accuracy {'Training': 0.9980988502502441, 'Validation': 1.0} 100\n",
            "Epoch 100: \n",
            "Accuracy train:0.9990494251251221, val:1.0\n",
            "LOSS train 0.006426851580329185 valid 0.0004445199017908408\n",
            "Training vs. Validation Loss {'Training': 0.006426851580329185, 'Validation': 0.0004445199017908408} 101\n",
            "Training vs. Validation accuracy {'Training': 0.9990494251251221, 'Validation': 1.0} 101\n",
            "Epoch 101: \n",
            "Accuracy train:0.999524712562561, val:1.0\n",
            "LOSS train 0.0020777792621269123 valid 8.699721473881539e-06\n",
            "Training vs. Validation Loss {'Training': 0.0020777792621269123, 'Validation': 8.699721473881539e-06} 102\n",
            "Training vs. Validation accuracy {'Training': 0.999524712562561, 'Validation': 1.0} 102\n",
            "Epoch 102: \n",
            "Accuracy train:0.9980988502502441, val:1.0\n",
            "LOSS train 0.005918268165637614 valid 1.9060222134659188e-05\n",
            "Training vs. Validation Loss {'Training': 0.005918268165637614, 'Validation': 1.9060222134659188e-05} 103\n",
            "Training vs. Validation accuracy {'Training': 0.9980988502502441, 'Validation': 1.0} 103\n",
            "Epoch 103: \n",
            "Accuracy train:0.9990494251251221, val:0.9987212419509888\n",
            "LOSS train 0.004833843884926126 valid 0.0034839619403843614\n",
            "Training vs. Validation Loss {'Training': 0.004833843884926126, 'Validation': 0.0034839619403843614} 104\n",
            "Training vs. Validation accuracy {'Training': 0.9990494251251221, 'Validation': 0.9987212419509888} 104\n",
            "Epoch 104: \n",
            "Accuracy train:0.9980988502502441, val:1.0\n",
            "LOSS train 0.008135550234680334 valid 5.192469686721157e-07\n",
            "Training vs. Validation Loss {'Training': 0.008135550234680334, 'Validation': 5.192469686721157e-07} 105\n",
            "Training vs. Validation accuracy {'Training': 0.9980988502502441, 'Validation': 1.0} 105\n",
            "Epoch 105: \n",
            "Accuracy train:0.9942965507507324, val:1.0\n",
            "LOSS train 0.035034293560784135 valid 0.00010288207345476863\n",
            "Training vs. Validation Loss {'Training': 0.035034293560784135, 'Validation': 0.00010288207345476863} 106\n",
            "Training vs. Validation accuracy {'Training': 0.9942965507507324, 'Validation': 1.0} 106\n",
            "Epoch 106: \n",
            "Accuracy train:0.9942965507507324, val:1.0\n",
            "LOSS train 0.027728061274124145 valid 0.0008061550508855486\n",
            "Training vs. Validation Loss {'Training': 0.027728061274124145, 'Validation': 0.0008061550508855486} 107\n",
            "Training vs. Validation accuracy {'Training': 0.9942965507507324, 'Validation': 1.0} 107\n",
            "Epoch 107: \n",
            "Accuracy train:0.9961977005004883, val:1.0\n",
            "LOSS train 0.006641468779795311 valid 1.136234702842076e-05\n",
            "Training vs. Validation Loss {'Training': 0.006641468779795311, 'Validation': 1.136234702842076e-05} 108\n",
            "Training vs. Validation accuracy {'Training': 0.9961977005004883, 'Validation': 1.0} 108\n",
            "Epoch 108: \n",
            "Accuracy train:0.9990494251251221, val:0.9987212419509888\n",
            "LOSS train 0.006460001478386694 valid 0.0015014259468364433\n",
            "Training vs. Validation Loss {'Training': 0.006460001478386694, 'Validation': 0.0015014259468364433} 109\n",
            "Training vs. Validation accuracy {'Training': 0.9990494251251221, 'Validation': 0.9987212419509888} 109\n",
            "Epoch 109: \n",
            "Accuracy train:0.9985741376876831, val:0.9987212419509888\n",
            "LOSS train 0.007429936879396097 valid 0.0019970301290281045\n",
            "Training vs. Validation Loss {'Training': 0.007429936879396097, 'Validation': 0.0019970301290281045} 110\n",
            "Training vs. Validation accuracy {'Training': 0.9985741376876831, 'Validation': 0.9987212419509888} 110\n",
            "Epoch 110: \n",
            "Accuracy train:0.9980988502502441, val:1.0\n",
            "LOSS train 0.006839454971634281 valid 6.096920500742176e-06\n",
            "Training vs. Validation Loss {'Training': 0.006839454971634281, 'Validation': 6.096920500742176e-06} 111\n",
            "Training vs. Validation accuracy {'Training': 0.9980988502502441, 'Validation': 1.0} 111\n",
            "Epoch 111: \n",
            "Accuracy train:0.9985741376876831, val:1.0\n",
            "LOSS train 0.005749050675684379 valid 6.644459893401233e-06\n",
            "Training vs. Validation Loss {'Training': 0.005749050675684379, 'Validation': 6.644459893401233e-06} 112\n",
            "Training vs. Validation accuracy {'Training': 0.9985741376876831, 'Validation': 1.0} 112\n",
            "Epoch 112: \n",
            "Accuracy train:0.999524712562561, val:1.0\n",
            "LOSS train 0.002685940292557148 valid 0.00024569088089457236\n",
            "Training vs. Validation Loss {'Training': 0.002685940292557148, 'Validation': 0.00024569088089457236} 113\n",
            "Training vs. Validation accuracy {'Training': 0.999524712562561, 'Validation': 1.0} 113\n",
            "Epoch 113: \n",
            "Accuracy train:0.9985741376876831, val:1.0\n",
            "LOSS train 0.005386694897872917 valid 3.159762285309675e-05\n",
            "Training vs. Validation Loss {'Training': 0.005386694897872917, 'Validation': 3.159762285309675e-05} 114\n",
            "Training vs. Validation accuracy {'Training': 0.9985741376876831, 'Validation': 1.0} 114\n",
            "Epoch 114: \n",
            "Accuracy train:0.999524712562561, val:1.0\n",
            "LOSS train 0.0014669571081618793 valid 7.993300308456464e-06\n",
            "Training vs. Validation Loss {'Training': 0.0014669571081618793, 'Validation': 7.993300308456464e-06} 115\n",
            "Training vs. Validation accuracy {'Training': 0.999524712562561, 'Validation': 1.0} 115\n",
            "Epoch 115: \n",
            "Accuracy train:1.0, val:1.0\n",
            "LOSS train 0.0015537790210352264 valid 0.0008302655862633401\n",
            "Training vs. Validation Loss {'Training': 0.0015537790210352264, 'Validation': 0.0008302655862633401} 116\n",
            "Training vs. Validation accuracy {'Training': 1.0, 'Validation': 1.0} 116\n",
            "Epoch 116: \n",
            "Accuracy train:0.9980988502502441, val:1.0\n",
            "LOSS train 0.008604462149340304 valid 0.00012899606888830406\n",
            "Training vs. Validation Loss {'Training': 0.008604462149340304, 'Validation': 0.00012899606888830406} 117\n",
            "Training vs. Validation accuracy {'Training': 0.9980988502502441, 'Validation': 1.0} 117\n",
            "Epoch 117: \n",
            "Accuracy train:0.9985741376876831, val:1.0\n",
            "LOSS train 0.005696928892224957 valid 2.5558638336198314e-05\n",
            "Training vs. Validation Loss {'Training': 0.005696928892224957, 'Validation': 2.5558638336198314e-05} 118\n",
            "Training vs. Validation accuracy {'Training': 0.9985741376876831, 'Validation': 1.0} 118\n",
            "Epoch 118: \n",
            "Accuracy train:0.999524712562561, val:1.0\n",
            "LOSS train 0.0032289230765992164 valid 2.4255930033689754e-06\n",
            "Training vs. Validation Loss {'Training': 0.0032289230765992164, 'Validation': 2.4255930033689754e-06} 119\n",
            "Training vs. Validation accuracy {'Training': 0.999524712562561, 'Validation': 1.0} 119\n",
            "Epoch 119: \n",
            "Accuracy train:0.999524712562561, val:1.0\n",
            "LOSS train 0.0032320865784935715 valid 4.227614424118231e-06\n",
            "Training vs. Validation Loss {'Training': 0.0032320865784935715, 'Validation': 4.227614424118231e-06} 120\n",
            "Training vs. Validation accuracy {'Training': 0.999524712562561, 'Validation': 1.0} 120\n",
            "Epoch 120: \n",
            "Accuracy train:0.9985741376876831, val:0.9987212419509888\n",
            "LOSS train 0.004720121442211543 valid 0.0011315070462419585\n",
            "Training vs. Validation Loss {'Training': 0.004720121442211543, 'Validation': 0.0011315070462419585} 121\n",
            "Training vs. Validation accuracy {'Training': 0.9985741376876831, 'Validation': 0.9987212419509888} 121\n",
            "Epoch 121: \n",
            "Accuracy train:0.9980988502502441, val:1.0\n",
            "LOSS train 0.005967553529766313 valid 1.6895513315628996e-05\n",
            "Training vs. Validation Loss {'Training': 0.005967553529766313, 'Validation': 1.6895513315628996e-05} 122\n",
            "Training vs. Validation accuracy {'Training': 0.9980988502502441, 'Validation': 1.0} 122\n",
            "Epoch 122: \n",
            "Accuracy train:0.999524712562561, val:1.0\n",
            "LOSS train 0.0024986662700401227 valid 1.832538679913398e-06\n",
            "Training vs. Validation Loss {'Training': 0.0024986662700401227, 'Validation': 1.832538679913398e-06} 123\n",
            "Training vs. Validation accuracy {'Training': 0.999524712562561, 'Validation': 1.0} 123\n",
            "Epoch 123: \n",
            "Accuracy train:1.0, val:1.0\n",
            "LOSS train 0.001266214963299314 valid 1.0538920542924046e-06\n",
            "Training vs. Validation Loss {'Training': 0.001266214963299314, 'Validation': 1.0538920542924046e-06} 124\n",
            "Training vs. Validation accuracy {'Training': 1.0, 'Validation': 1.0} 124\n",
            "Epoch 124: \n",
            "Accuracy train:0.999524712562561, val:1.0\n",
            "LOSS train 0.0014957414212662297 valid 7.279485088718118e-06\n",
            "Training vs. Validation Loss {'Training': 0.0014957414212662297, 'Validation': 7.279485088718118e-06} 125\n",
            "Training vs. Validation accuracy {'Training': 0.999524712562561, 'Validation': 1.0} 125\n",
            "Epoch 125: \n",
            "Accuracy train:0.999524712562561, val:0.9961636662483215\n",
            "LOSS train 0.006235449616634149 valid 0.014065923442103667\n",
            "Training vs. Validation Loss {'Training': 0.006235449616634149, 'Validation': 0.014065923442103667} 126\n",
            "Training vs. Validation accuracy {'Training': 0.999524712562561, 'Validation': 0.9961636662483215} 126\n",
            "Epoch 126: \n",
            "Accuracy train:0.9985741376876831, val:1.0\n",
            "LOSS train 0.01162136110952871 valid 6.111548176562787e-06\n",
            "Training vs. Validation Loss {'Training': 0.01162136110952871, 'Validation': 6.111548176562787e-06} 127\n",
            "Training vs. Validation accuracy {'Training': 0.9985741376876831, 'Validation': 1.0} 127\n",
            "Epoch 127: \n",
            "Accuracy train:0.999524712562561, val:0.9974424839019775\n",
            "LOSS train 0.009936637549490458 valid 0.01081272493161567\n",
            "Training vs. Validation Loss {'Training': 0.009936637549490458, 'Validation': 0.01081272493161567} 128\n",
            "Training vs. Validation accuracy {'Training': 0.999524712562561, 'Validation': 0.9974424839019775} 128\n",
            "Epoch 128: \n",
            "Accuracy train:0.9985741376876831, val:1.0\n",
            "LOSS train 0.005629145109433569 valid 4.700275862301595e-06\n",
            "Training vs. Validation Loss {'Training': 0.005629145109433569, 'Validation': 4.700275862301595e-06} 129\n",
            "Training vs. Validation accuracy {'Training': 0.9985741376876831, 'Validation': 1.0} 129\n",
            "Epoch 129: \n",
            "Accuracy train:0.999524712562561, val:1.0\n",
            "LOSS train 0.005688122875450011 valid 0.00089084192003\n",
            "Training vs. Validation Loss {'Training': 0.005688122875450011, 'Validation': 0.00089084192003} 130\n",
            "Training vs. Validation accuracy {'Training': 0.999524712562561, 'Validation': 1.0} 130\n",
            "Epoch 130: \n",
            "Accuracy train:0.9985741376876831, val:1.0\n",
            "LOSS train 0.002128027620842058 valid 0.0009201449362488401\n",
            "Training vs. Validation Loss {'Training': 0.002128027620842058, 'Validation': 0.0009201449362488401} 131\n",
            "Training vs. Validation accuracy {'Training': 0.9985741376876831, 'Validation': 1.0} 131\n",
            "Epoch 131: \n",
            "Accuracy train:1.0, val:1.0\n",
            "LOSS train 0.004501073206037685 valid 0.0002532539636750375\n",
            "Training vs. Validation Loss {'Training': 0.004501073206037685, 'Validation': 0.0002532539636750375} 132\n",
            "Training vs. Validation accuracy {'Training': 1.0, 'Validation': 1.0} 132\n",
            "Epoch 132: \n",
            "Accuracy train:0.9952471256256104, val:0.9795396327972412\n",
            "LOSS train 0.02644520183974168 valid 0.08586745918410088\n",
            "Training vs. Validation Loss {'Training': 0.02644520183974168, 'Validation': 0.08586745918410088} 133\n",
            "Training vs. Validation accuracy {'Training': 0.9952471256256104, 'Validation': 0.9795396327972412} 133\n",
            "Epoch 133: \n",
            "Accuracy train:0.9976235628128052, val:1.0\n",
            "LOSS train 0.008061516268410415 valid 0.000383439783487205\n",
            "Training vs. Validation Loss {'Training': 0.008061516268410415, 'Validation': 0.000383439783487205} 134\n",
            "Training vs. Validation accuracy {'Training': 0.9976235628128052, 'Validation': 1.0} 134\n",
            "Epoch 134: \n",
            "Accuracy train:0.9985741376876831, val:0.9987212419509888\n",
            "LOSS train 0.006273324167261548 valid 0.003097667032310625\n",
            "Training vs. Validation Loss {'Training': 0.006273324167261548, 'Validation': 0.003097667032310625} 135\n",
            "Training vs. Validation accuracy {'Training': 0.9985741376876831, 'Validation': 0.9987212419509888} 135\n",
            "Epoch 135: \n",
            "Accuracy train:0.9980988502502441, val:1.0\n",
            "LOSS train 0.007729113315621842 valid 3.3101396349904944e-05\n",
            "Training vs. Validation Loss {'Training': 0.007729113315621842, 'Validation': 3.3101396349904944e-05} 136\n",
            "Training vs. Validation accuracy {'Training': 0.9980988502502441, 'Validation': 1.0} 136\n",
            "Epoch 136: \n",
            "Accuracy train:0.9990494251251221, val:1.0\n",
            "LOSS train 0.0021665811972791248 valid 3.368301144932029e-05\n",
            "Training vs. Validation Loss {'Training': 0.0021665811972791248, 'Validation': 3.368301144932029e-05} 137\n",
            "Training vs. Validation accuracy {'Training': 0.9990494251251221, 'Validation': 1.0} 137\n",
            "Epoch 137: \n",
            "Accuracy train:0.999524712562561, val:1.0\n",
            "LOSS train 0.0028773616200370904 valid 0.00011228589474332473\n",
            "Training vs. Validation Loss {'Training': 0.0028773616200370904, 'Validation': 0.00011228589474332473} 138\n",
            "Training vs. Validation accuracy {'Training': 0.999524712562561, 'Validation': 1.0} 138\n",
            "Epoch 138: \n",
            "Accuracy train:0.9990494251251221, val:1.0\n",
            "LOSS train 0.0019019578006326861 valid 2.7264608961630188e-06\n",
            "Training vs. Validation Loss {'Training': 0.0019019578006326861, 'Validation': 2.7264608961630188e-06} 139\n",
            "Training vs. Validation accuracy {'Training': 0.9990494251251221, 'Validation': 1.0} 139\n",
            "Epoch 139: \n",
            "Accuracy train:0.9980988502502441, val:1.0\n",
            "LOSS train 0.013107577666687575 valid 0.0011039156254448734\n",
            "Training vs. Validation Loss {'Training': 0.013107577666687575, 'Validation': 0.0011039156254448734} 140\n",
            "Training vs. Validation accuracy {'Training': 0.9980988502502441, 'Validation': 1.0} 140\n",
            "Epoch 140: \n",
            "Accuracy train:1.0, val:1.0\n",
            "LOSS train 0.0014712478160695268 valid 9.592520110512925e-06\n",
            "Training vs. Validation Loss {'Training': 0.0014712478160695268, 'Validation': 9.592520110512925e-06} 141\n",
            "Training vs. Validation accuracy {'Training': 1.0, 'Validation': 1.0} 141\n",
            "Epoch 141: \n",
            "Accuracy train:0.999524712562561, val:0.9987212419509888\n",
            "LOSS train 0.0028911224845850343 valid 0.003530948774389031\n",
            "Training vs. Validation Loss {'Training': 0.0028911224845850343, 'Validation': 0.003530948774389031} 142\n",
            "Training vs. Validation accuracy {'Training': 0.999524712562561, 'Validation': 0.9987212419509888} 142\n",
            "Epoch 142: \n",
            "Accuracy train:0.9990494251251221, val:1.0\n",
            "LOSS train 0.007752559233980899 valid 0.00025906791123386785\n",
            "Training vs. Validation Loss {'Training': 0.007752559233980899, 'Validation': 0.00025906791123386785} 143\n",
            "Training vs. Validation accuracy {'Training': 0.9990494251251221, 'Validation': 1.0} 143\n",
            "Epoch 143: \n",
            "Accuracy train:0.999524712562561, val:1.0\n",
            "LOSS train 0.004920737078142544 valid 5.953518771018018e-05\n",
            "Training vs. Validation Loss {'Training': 0.004920737078142544, 'Validation': 5.953518771018018e-05} 144\n",
            "Training vs. Validation accuracy {'Training': 0.999524712562561, 'Validation': 1.0} 144\n",
            "Epoch 144: \n",
            "Accuracy train:0.9985741376876831, val:0.9897698163986206\n",
            "LOSS train 0.011513480162326438 valid 0.04804639483873174\n",
            "Training vs. Validation Loss {'Training': 0.011513480162326438, 'Validation': 0.04804639483873174} 145\n",
            "Training vs. Validation accuracy {'Training': 0.9985741376876831, 'Validation': 0.9897698163986206} 145\n",
            "Epoch 145: \n",
            "Accuracy train:0.9966729879379272, val:1.0\n",
            "LOSS train 0.008202523255742975 valid 0.00018987392693670113\n",
            "Training vs. Validation Loss {'Training': 0.008202523255742975, 'Validation': 0.00018987392693670113} 146\n",
            "Training vs. Validation accuracy {'Training': 0.9966729879379272, 'Validation': 1.0} 146\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-5a367f15000e>\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-25-074170e74e9a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(trainloader, val_loader, model, loss_function, early_stopper, optimizer)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;31m####################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-9840feccc378>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m         ))\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_relu_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/flatten.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend_dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_label = label_dict_from_config_file(\"hand_gesture.yaml\")\n",
        "DATA_FOLDER_PATH=\"./data/\"\n",
        "testset = CustomImageDataset(os.path.join(DATA_FOLDER_PATH,\"landmark_test.csv\"))\n",
        "\n",
        "# Test DataLoader instantiation\n",
        "################## Your Code Here ################## Q6\n",
        "''' Hoàn thành code bên dưới để  khởi tạo DataLoader cho testset with batch size\n",
        "20, không cho phép shuffle\n",
        "'''\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=20, shuffle=False)\n",
        "####################################################\n",
        "\n",
        "\n",
        "\n",
        "network = NeuralNetwork()\n",
        "network.load_state_dict(torch.load(best_model_path, weights_only=False))\n",
        "\n",
        "network.eval()\n",
        "acc_test = Accuracy(num_classes=len(list_label), task='MULTICLASS')\n",
        "for i, test_data in enumerate(test_loader):\n",
        "    test_input, test_label = test_data\n",
        "    ################## Your Code Here ################## Q7\n",
        "    '''Hoàn thành code bên dưới để  predict class của cử chỉ và update accuracy\n",
        "    với kết quả predict và true labels\n",
        "    '''\n",
        "    preds =preds = network(test_input)\n",
        "    acc_test.update(preds, test_label)\n",
        "\n",
        "    ####################################################\n",
        "\n",
        "print(network.__class__.__name__)\n",
        "print(f\"Accuracy of model:{acc_test.compute().item()}\")\n",
        "print(\"========================================================================\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqUXbjbdX-ey",
        "outputId": "28e6fadc-3647-4e09-82d3-b66a1a7bb823"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork\n",
            "Accuracy of model:0.9981378316879272\n",
            "========================================================================\n"
          ]
        }
      ]
    }
  ]
}